{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autokeras_regressor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zSmzFqGbNQuikI-ijx_kxzmg3tv8cUOY",
      "authorship_tag": "ABX9TyNbVZrqBYscNC9PISzP8k5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itsuki-Hamano123/auto_ml/blob/master/auto-keras/california_housing/autokeras_regressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGDmOuUygC-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dcbe2b7-993c-4858-8765-a16323411294"
      },
      "source": [
        "%pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1\n",
        "%pip install autokeras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1\n",
            "  Cloning https://github.com/keras-team/keras-tuner.git (to revision 1.0.2rc1) to /tmp/pip-req-build-c57m_1bg\n",
            "  Running command git clone -q https://github.com/keras-team/keras-tuner.git /tmp/pip-req-build-c57m_1bg\n",
            "  Running command git checkout -q 0fb69434a132093518e0e53d40020145ae192629\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (20.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner==1.0.2rc1) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner==1.0.2rc1) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner==1.0.2rc1) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner==1.0.2rc1) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner==1.0.2rc1) (0.16.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2rc1-cp36-none-any.whl size=85424 sha256=c06285553119fcabbdf312f3c56a7725966602f76610d57aae39a360351ba6f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rqonbuf5/wheels/af/c9/7c/6ea01f9753a5dd1484136b4cb7b33a0a7fba253e5c74ade5af\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=2e3d5e02558bf7bcc77ca46588486f6fea14c7ef7159b2d15676769df3020071\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.2rc1 terminaltables-3.1.0\n",
            "Collecting autokeras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/12/01b893f0e2f5865f0fdd2c47a99fb0a96ad3263e3eaa1be04f9ec9979dc4/autokeras-1.0.8-py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from autokeras) (20.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (0.16.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.31.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->autokeras) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras) (49.6.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (2.10)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
            "Installing collected packages: autokeras\n",
            "Successfully installed autokeras-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8AcVTMwgS4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "cc9cddbb-d861-41c7-d1f7-47c70776594c"
      },
      "source": [
        "%pip show autokeras\n",
        "%pip show keras-tuner\n",
        "%pip show tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: autokeras\n",
            "Version: 1.0.8\n",
            "Summary: AutoML for deep learning\n",
            "Home-page: http://autokeras.com\n",
            "Author: Data Analytics at Texas A&M (DATA) Lab, Keras Team\n",
            "Author-email: jhfjhfj1@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: packaging, pandas, scikit-learn, tensorflow\n",
            "Required-by: \n",
            "Name: keras-tuner\n",
            "Version: 1.0.2rc1\n",
            "Summary: Hypertuner for Keras\n",
            "Home-page: https://github.com/keras-team/keras-tuner\n",
            "Author: The Keras Tuner authors\n",
            "Author-email: kerastuner@google.com\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: packaging, colorama, scikit-learn, future, tqdm, tabulate, requests, terminaltables, scipy, numpy\n",
            "Required-by: \n",
            "Name: tensorflow\n",
            "Version: 2.3.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: gast, wheel, keras-preprocessing, opt-einsum, google-pasta, grpcio, numpy, scipy, absl-py, tensorflow-estimator, termcolor, six, tensorboard, protobuf, astunparse, wrapt, h5py\n",
            "Required-by: fancyimpute, autokeras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT3C6q5wgb7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8bdb4681-a9b2-47f6-8c27-438fa4c903fe"
      },
      "source": [
        "%cd /content/drive/My Drive/機械学習練習/AutoML/auto-keras/california_housing\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/機械学習練習/AutoML/auto-keras/california_housing\n",
            "autokeras_model.ipynb  \u001b[0m\u001b[01;34mauto_keras_outputs\u001b[0m/  \u001b[01;34mdatasets\u001b[0m/  fetch_data.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn0-ISFsgxKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cloudpickle, os, pprint\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
        "\n",
        "import autokeras as ak\n",
        "from autokeras import StructuredDataRegressor\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6OZmQ0Pni6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F_COLS = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
        "TARGET_COL = 'MedHouseVal'\n",
        "\n",
        "SEED = 7\n",
        "MAX_TRIAL_NUM = 10\n",
        "MODEL_OUTPUT_DIR = 'auto_keras_outputs'\n",
        "\n",
        "EPOCH = 50\n",
        "es = EarlyStopping(patience=3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiyDjpfynfYi",
        "colab_type": "text"
      },
      "source": [
        "## 前処理していないデータで回帰モデルを構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MtEW4m3g8LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trial_name = 'origin_data_trial'\n",
        "\n",
        "reg = StructuredDataRegressor(max_trials=MAX_TRIAL_NUM,\n",
        "                              seed=SEED,\n",
        "                              directory=os.path.join(MODEL_OUTPUT_DIR, trial_name),\n",
        "                              overwrite=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDjsi5GAjRBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "44dfafe7-010a-49df-e380-4c53198a4f84"
      },
      "source": [
        "%time\n",
        "data_path = 'datasets/origin'\n",
        "train_csv = 'train.csv'\n",
        "val_csv = 'val.csv'\n",
        "\n",
        "reg.fit(x=os.path.join(data_path, train_csv),\n",
        "        y=TARGET_COL,\n",
        "        validation_data=(os.path.join(data_path, val_csv), TARGET_COL),\n",
        "        epochs=EPOCH,\n",
        "        callbacks=[es],\n",
        "        verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 01m 34s]\n",
            "val_loss: 0.30827993154525757\n",
            "\n",
            "Best val_loss So Far: 0.30827993154525757\n",
            "Total elapsed time: 00h 07m 07s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8dgR6Psn2Mr",
        "colab_type": "text"
      },
      "source": [
        "## 前処理済みのデータで回帰モデルを構築\n",
        "行った前処理\n",
        "- 標準化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w2bWwimn8Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_trial_name = 'std_data_trial'\n",
        "\n",
        "std_reg = StructuredDataRegressor(max_trials=MAX_TRIAL_NUM,\n",
        "                                  seed=SEED,\n",
        "                                  directory=os.path.join(MODEL_OUTPUT_DIR, std_trial_name),\n",
        "                                  overwrite=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4m2QzJoU3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "961a8339-9571-478a-ad11-d0cdaebf30d0"
      },
      "source": [
        "%time\n",
        "std_data_path = 'datasets/std'\n",
        "std_train_csv = 'std_train.csv'\n",
        "std_val_csv = 'std_val.csv'\n",
        "\n",
        "std_reg.fit(x=os.path.join(std_data_path, std_train_csv), \n",
        "            y=TARGET_COL,\n",
        "            validation_data=(os.path.join(std_data_path, std_val_csv), TARGET_COL),\n",
        "            epochs=EPOCH,\n",
        "            callbacks=[es],\n",
        "            verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 01m 37s]\n",
            "val_loss: 0.22447553277015686\n",
            "\n",
            "Best val_loss So Far: 0.22447553277015686\n",
            "Total elapsed time: 00h 11m 45s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgIsUJfbz_bw",
        "colab_type": "text"
      },
      "source": [
        "## 回帰モデルの構造を比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b29_Tr40zcYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "7a22d798-36ea-4f6e-9e02-4252bd666700"
      },
      "source": [
        "reg.export_model().summary()\n",
        "std_reg.export_model().summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8)]               0         \n",
            "_________________________________________________________________\n",
            "multi_category_encoding (Mul (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 8)                 17        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "regression_head_1 (Dense)    (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,706\n",
            "Trainable params: 2,689\n",
            "Non-trainable params: 17\n",
            "_________________________________________________________________\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8)]               0         \n",
            "_________________________________________________________________\n",
            "multi_category_encoding (Mul (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 8)                 17        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "regression_head_1 (Dense)    (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 9,042\n",
            "Trainable params: 9,025\n",
            "Non-trainable params: 17\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyAZKWXjpWIN",
        "colab_type": "text"
      },
      "source": [
        "## モデルの評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oQ8GIWTw6MF",
        "colab_type": "text"
      },
      "source": [
        "### 正解データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgK6jYMfrd0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f513703-cc7d-44ab-9b7d-408173be267c"
      },
      "source": [
        "%time\n",
        "\n",
        "def _load_y_from_csv(csv_path, y_col_name):\n",
        "  '''CSVファイルから予測対象の列のみ抽出'''\n",
        "  df = pd.read_csv(csv_path, header=0)\n",
        "  return df[y_col_name]\n",
        "\n",
        "\n",
        "def load_y_from_csv_files(data_path, csv_names, y_col_name):\n",
        "  '''CSVファイルリストから予測対象の列を抽出\n",
        "  Parameters\n",
        "  -----\n",
        "  data_path : string\n",
        "  csv_names : list of string\n",
        "  y_col_name : string\n",
        "\n",
        "  Returns\n",
        "  -----\n",
        "  data : dict\n",
        "    {csv_name1:y_df2, csv_name2:y_df2, csv_name3:y_df3,,,,,}\n",
        "  '''\n",
        "  data = {}\n",
        "  for csv_name in csv_names:\n",
        "    csv_path = os.path.join(data_path, csv_name)\n",
        "    data[csv_name] = _load_y_from_csv(csv_path, y_col_name)\n",
        "  return data\n",
        "\n",
        "\n",
        "test_csv = 'test.csv'\n",
        "std_test_csv = 'std_test.csv'\n",
        "\n",
        "origin_y = load_y_from_csv_files(data_path=data_path, csv_names=[train_csv, val_csv, test_csv],\n",
        "                                 y_col_name=TARGET_COL)\n",
        "std_y = load_y_from_csv_files(data_path=std_data_path, csv_names=[std_train_csv, std_val_csv, std_test_csv],\n",
        "                              y_col_name=TARGET_COL)\n",
        "pprint.pprint(origin_y)\n",
        "pprint.pprint(std_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.25 µs\n",
            "{'test.csv': 0       3.60000\n",
            "1       3.36000\n",
            "2       2.69900\n",
            "3       2.87500\n",
            "4       5.00001\n",
            "         ...   \n",
            "4123    3.43700\n",
            "4124    3.25900\n",
            "4125    2.00000\n",
            "4126    4.06500\n",
            "4127    4.13700\n",
            "Name: MedHouseVal, Length: 4128, dtype: float64,\n",
            " 'train.csv': 0        1.285\n",
            "1        1.875\n",
            "2        0.525\n",
            "3        0.913\n",
            "4        2.860\n",
            "         ...  \n",
            "13204    3.305\n",
            "13205    1.616\n",
            "13206    1.210\n",
            "13207    1.275\n",
            "13208    1.696\n",
            "Name: MedHouseVal, Length: 13209, dtype: float64,\n",
            " 'val.csv': 0       0.863\n",
            "1       1.485\n",
            "2       1.335\n",
            "3       1.149\n",
            "4       1.405\n",
            "        ...  \n",
            "3298    1.739\n",
            "3299    0.792\n",
            "3300    0.559\n",
            "3301    0.555\n",
            "3302    0.875\n",
            "Name: MedHouseVal, Length: 3303, dtype: float64}\n",
            "{'std_test.csv': 0       1.353497\n",
            "1       1.143981\n",
            "2       0.566937\n",
            "3       0.720582\n",
            "4       2.575687\n",
            "          ...   \n",
            "4123    1.211201\n",
            "4124    1.055809\n",
            "4125   -0.043281\n",
            "4126    1.759436\n",
            "4127    1.822291\n",
            "Name: MedHouseVal, Length: 4128, dtype: float64,\n",
            " 'std_train.csv': 0       -0.667466\n",
            "1       -0.152404\n",
            "2       -1.330936\n",
            "3       -0.992217\n",
            "4        0.707487\n",
            "           ...   \n",
            "13204    1.095966\n",
            "13205   -0.378508\n",
            "13206   -0.732940\n",
            "13207   -0.676196\n",
            "13208   -0.308669\n",
            "Name: MedHouseVal, Length: 13209, dtype: float64,\n",
            " 'std_val.csv': 0      -1.035867\n",
            "1      -0.492869\n",
            "2      -0.623817\n",
            "3      -0.786193\n",
            "4      -0.562708\n",
            "          ...   \n",
            "3298   -0.271130\n",
            "3299   -1.097849\n",
            "3300   -1.301255\n",
            "3301   -1.304747\n",
            "3302   -1.025391\n",
            "Name: MedHouseVal, Length: 3303, dtype: float64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Ar42qIx1xJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "94b88648-5d39-4349-f298-700ab465ba9c"
      },
      "source": [
        "# 標準化器も読み込んでおく\n",
        "def load_pkl(path):\n",
        "  '''pklファイルの読み込み'''\n",
        "  with open(path, 'rb') as f:\n",
        "    obj = cloudpickle.load(f)\n",
        "  return obj\n",
        "\n",
        "\n",
        "pkl_name = 'std_scaler.pkl'\n",
        "std_scaler = load_pkl(os.path.join(std_data_path, pkl_name))\n",
        "std_scaler"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZniAHjZbw-DQ",
        "colab_type": "text"
      },
      "source": [
        "### 評価指標の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NibekHKYoqyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _calc_score(y_true, y_pred, sklearn_metric):\n",
        "  '''sklearnの評価指標のスコアを計算'''\n",
        "  score = sklearn_metric(y_true=y_true, y_pred=y_pred)\n",
        "  return score\n",
        "\n",
        "\n",
        "def evaluete_sk_metrics(y_true, y_pred, sklearn_metrics):\n",
        "  '''sklearnの各種、評価関数を使用'''\n",
        "  result = {}\n",
        "  for sk_metric in sklearn_metrics:\n",
        "    result[sk_metric.__name__] = _calc_score(y_true=y_true, y_pred=y_pred, sklearn_metric=sk_metric)\n",
        "  return result"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYdr4vzwTyph",
        "colab_type": "text"
      },
      "source": [
        "### 推論結果の取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq19hkOfyyXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_multiple_times(model, inputs, input_names):\n",
        "  '''何度か推論'''\n",
        "  pred = {}\n",
        "  for input, name in zip(inputs, input_names):\n",
        "    pred[name] = model.predict(x=input)\n",
        "  return pred"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAG5YOfFSMVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0e1570e4-8a4c-4958-c888-4ffd324051a4"
      },
      "source": [
        "%time\n",
        "reg_inputs = [os.path.join(data_path, train_csv), os.path.join(data_path, val_csv),\n",
        "              os.path.join(data_path, test_csv)]\n",
        "reg_input_names = [train_csv, val_csv, test_csv]\n",
        "\n",
        "std_reg_inputs = [os.path.join(std_data_path, std_train_csv), os.path.join(std_data_path, std_val_csv),\n",
        "                  os.path.join(std_data_path, std_test_csv)]\n",
        "std_input_names = [std_train_csv, std_val_csv, std_test_csv]\n",
        "\n",
        "\n",
        "reg_preds = predict_multiple_times(model=reg, inputs=reg_inputs, input_names=reg_input_names)\n",
        "std_reg_preds = predict_multiple_times(model=std_reg, inputs=std_reg_inputs, input_names=std_input_names)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.96 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gywOo12CyvVs",
        "colab_type": "text"
      },
      "source": [
        "### モデルの評価の実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCc4yjubTuZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "52422b7b-38c7-457f-96ba-bdbc97a67eac"
      },
      "source": [
        "SK_METRICS=[r2_score, explained_variance_score, mean_squared_error]\n",
        "\n",
        "eval_scores = {trial_name: {}, std_trial_name: {}}\n",
        "\n",
        "for csv_name in [train_csv, val_csv, test_csv]:\n",
        "  eval_scores[trial_name][csv_name] = evaluete_sk_metrics(y_true=origin_y[csv_name],\n",
        "                                                          y_pred=reg_preds[csv_name], sklearn_metrics=SK_METRICS)\n",
        "\n",
        "for csv_name in [std_train_csv, std_val_csv, std_test_csv]:\n",
        "  eval_scores[std_trial_name][csv_name] = evaluete_sk_metrics(y_true=std_y[csv_name],\n",
        "                                                              y_pred=std_reg_preds[csv_name], sklearn_metrics=SK_METRICS)\n",
        "\n",
        "pprint.pprint(eval_scores)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'origin_data_trial': {'test.csv': {'explained_variance_score': 0.764497364700181,\n",
            "                                    'mean_squared_error': 0.3172162537811974,\n",
            "                                    'r2_score': 0.7641543761325529},\n",
            "                       'train.csv': {'explained_variance_score': 0.7988240701046778,\n",
            "                                     'mean_squared_error': 0.2641440815796903,\n",
            "                                     'r2_score': 0.7986943587905473},\n",
            "                       'val.csv': {'explained_variance_score': 0.778467302204158,\n",
            "                                   'mean_squared_error': 0.3082799718189581,\n",
            "                                   'r2_score': 0.7779319708087133}},\n",
            " 'std_data_trial': {'std_test.csv': {'explained_variance_score': 0.7748218425954454,\n",
            "                                     'mean_squared_error': 0.2313804887467392,\n",
            "                                     'r2_score': 0.7742727121850517},\n",
            "                    'std_train.csv': {'explained_variance_score': 0.8089734704902763,\n",
            "                                      'mean_squared_error': 0.19118862505093268,\n",
            "                                      'r2_score': 0.8088113749490673},\n",
            "                    'std_val.csv': {'explained_variance_score': 0.7884612786337593,\n",
            "                                    'mean_squared_error': 0.2244755335076629,\n",
            "                                    'r2_score': 0.7878247712418275}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMXzAaVhc5tb",
        "colab_type": "text"
      },
      "source": [
        "#### モデルの予測値を標準化から復元し評価する場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VaMiYHIdGyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "52b7363a-b69a-4cdb-f883-448f8e3a07fb"
      },
      "source": [
        "# scalerの入力形状に合わせるためデータを読み込み\n",
        "std_train_df = pd.read_csv(os.path.join(std_data_path, std_train_csv), header=0)\n",
        "std_val_df = pd.read_csv(os.path.join(std_data_path, std_val_csv))\n",
        "std_test_df = pd.read_csv(os.path.join(std_data_path, std_test_csv))\n",
        "\n",
        "\n",
        "def inverse_scale_values(values, scaler):\n",
        "  '''scalerを使って値の復元'''\n",
        "  return scaler.inverse_transform(values)\n",
        "\n",
        "\n",
        "inverse_scale_preds = {}\n",
        "# 目的変数をモデルの予測値に置き換え\n",
        "for df, csv_name, key in zip([std_train_df, std_val_df, std_test_df], [std_train_csv, std_val_csv, std_test_csv], \n",
        "                             [train_csv, val_csv, test_csv]):\n",
        "  df[TARGET_COL] = std_reg_preds[csv_name]\n",
        "  tmp_df = pd.DataFrame(inverse_scale_values(df.values, std_scaler), columns=F_COLS+[TARGET_COL])\n",
        "  inverse_scale_preds[key] = tmp_df[TARGET_COL].values\n",
        "\n",
        "inverse_scale_preds"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test.csv': array([2.22010661, 2.97332405, 2.42588612, ..., 1.64286388, 3.44026607,\n",
              "        4.34359164]),\n",
              " 'train.csv': array([1.46262931, 1.90931729, 0.84499029, ..., 0.94900842, 1.64495533,\n",
              "        1.61374175]),\n",
              " 'val.csv': array([1.06052579, 0.81792568, 1.315066  , ..., 1.26904183, 0.93166764,\n",
              "        1.30016598])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMo92phMzV7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "267b76d3-56c6-4e89-853a-07d4b0b056f9"
      },
      "source": [
        "# 標準化された値を復元した場合の評価スコア\n",
        "for csv_name in [train_csv, val_csv, test_csv]:\n",
        "  eval_scores[std_trial_name][csv_name] = evaluete_sk_metrics(y_true=origin_y[csv_name],\n",
        "                                                              y_pred=inverse_scale_preds[csv_name],\n",
        "                                                              sklearn_metrics=SK_METRICS)\n",
        "\n",
        "pprint.pprint(eval_scores)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'origin_data_trial': {'test.csv': {'explained_variance_score': 0.764497364700181,\n",
            "                                    'mean_squared_error': 0.3172162537811974,\n",
            "                                    'r2_score': 0.7641543761325529},\n",
            "                       'train.csv': {'explained_variance_score': 0.7988240701046778,\n",
            "                                     'mean_squared_error': 0.2641440815796903,\n",
            "                                     'r2_score': 0.7986943587905473},\n",
            "                       'val.csv': {'explained_variance_score': 0.778467302204158,\n",
            "                                   'mean_squared_error': 0.3082799718189581,\n",
            "                                   'r2_score': 0.7779319708087133}},\n",
            " 'std_data_trial': {'std_test.csv': {'explained_variance_score': 0.7748218425954454,\n",
            "                                     'mean_squared_error': 0.2313804887467392,\n",
            "                                     'r2_score': 0.7742727121850517},\n",
            "                    'std_train.csv': {'explained_variance_score': 0.8089734704902763,\n",
            "                                      'mean_squared_error': 0.19118862505093268,\n",
            "                                      'r2_score': 0.8088113749490673},\n",
            "                    'std_val.csv': {'explained_variance_score': 0.7884612786337593,\n",
            "                                    'mean_squared_error': 0.2244755335076629,\n",
            "                                    'r2_score': 0.7878247712418275},\n",
            "                    'test.csv': {'explained_variance_score': 0.7748218425954454,\n",
            "                                 'mean_squared_error': 0.3036069249141211,\n",
            "                                 'r2_score': 0.7742727121850517},\n",
            "                    'train.csv': {'explained_variance_score': 0.8089734704902762,\n",
            "                                  'mean_squared_error': 0.25086899437665133,\n",
            "                                  'r2_score': 0.8088113749490673},\n",
            "                    'val.csv': {'explained_variance_score': 0.7884612786337593,\n",
            "                                'mean_squared_error': 0.2945465575592045,\n",
            "                                'r2_score': 0.7878247712418275}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbH2-XoZiF5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}